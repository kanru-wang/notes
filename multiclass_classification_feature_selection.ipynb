{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both methods work for multi-class feature selection.\n",
    "\n",
    "\n",
    "# Method 1: Use ANOVA F-value to find useful features (for binary / multiclass) classification\n",
    "\n",
    "See https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide-3.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import special\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.feature_selection.univariate_selection import check_X_y, safe_mask, as_float_array, safe_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'col1':   [11 , 10 , 10 , 100 ,100 ,102 ,51 , 50 , 601 ,600],# col1 is perfect \n",
    "        'col2':   [1,   1.1, 1,   11,  10,  10,  5,   5,   5,   5],  # col2 is perfect, excpet class \"c\" and \"d\"\n",
    "        'col3':   [10 , 11 , 100 ,100 ,101 ,100 ,50 , 50 , 51 , 50], # col3 is 10x col4\n",
    "        'col4':   [1,   1.1, 10,  10,  10.1,10,  5,   5,   5.1, 5],  # col3 is 10x col4\n",
    "        'col5':   [1,   1,   1.1, 1,   1,   1.1, 1,   1.1, 1.1, 1],  # col5 is useless\n",
    "        'target': [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"d\", \"d\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = SelectKBest(f_classif, k = 2).fit(df.iloc[:,0:5], df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Col 1 should be the best feature, followed by Col 2\n",
    "- Col 3 and Col 4 should be the same\n",
    "- Col 5 should be the worst feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.26015462e+05, 3.88680198e+02, 2.38430002e+00, 2.38430002e+00,\n",
       "       5.71428571e-02])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, pval = f_classif(df.iloc[:,0:5], df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.26015462e+05, 3.88680198e+02, 2.38430002e+00, 2.38430002e+00,\n",
       "       5.71428571e-02])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51569085e-15, 2.92912877e-07, 1.68061973e-01, 1.68061973e-01,\n",
       "       9.80413827e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dig into the details of `f_classif's f_oneway` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "??f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:5]\n",
    "y = df.target\n",
    "args = [X[safe_mask(X, y == k)] for k in np.unique(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.20333333e+02 3.20333333e+00 4.88033333e+03 4.88033333e+01\n",
      " 3.20333333e+00]\n",
      "[3.07216667e+04 3.23536667e+02 3.50806667e+04 3.50806667e+02\n",
      " 6.40666667e+00]\n",
      "[3.58221667e+04 3.73536667e+02 4.00806667e+04 4.00806667e+02\n",
      " 8.61166667e+00]\n",
      "[7.57022667e+05 4.23536667e+02 4.51811667e+04 4.51811667e+02\n",
      " 1.08166667e+01]\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(args)\n",
    "args = [as_float_array(a) for a in args]\n",
    "n_samples_per_class = np.array([a.shape[0] for a in args])\n",
    "n_samples = np.sum(n_samples_per_class)\n",
    "ss_alldata = sum(safe_sqr(a).sum(axis=0) for a in args)\n",
    "sums_args = [np.asarray(a.sum(axis=0)) for a in args]\n",
    "square_of_sums_alldata = sum(sums_args) ** 2\n",
    "square_of_sums_args = [s ** 2 for s in sums_args]\n",
    "sstot = ss_alldata - square_of_sums_alldata / float(n_samples)\n",
    "ssbn = 0.\n",
    "for k, _ in enumerate(args):\n",
    "    ssbn += square_of_sums_args[k] / n_samples_per_class[k]\n",
    "    print(ssbn)\n",
    "ssbn -= square_of_sums_alldata / float(n_samples)\n",
    "sswn = sstot - ssbn\n",
    "dfbn = n_classes - 1\n",
    "dfwn = n_samples - n_classes\n",
    "msb = ssbn / float(dfbn)\n",
    "msw = sswn / float(dfwn)\n",
    "constant_features_idx = np.where(msw == 0.)[0]\n",
    "\n",
    "f = msb / msw\n",
    "# flatten matrix to vector in sparse case\n",
    "f = np.asarray(f).ravel()\n",
    "prob = special.fdtrc(dfbn, dfwn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.89700167e+05, 1.30855667e+02, 6.36826667e+03, 6.36826667e+01,\n",
       "       6.66666667e-04])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33333333e+00, 6.73333333e-01, 5.34183333e+03, 5.34183333e+01,\n",
       "       2.33333333e-02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sswn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.897045e+05, 1.315290e+02, 1.171010e+04, 1.171010e+02,\n",
       "       2.400000e-02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sstot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: phik\n",
    "\n",
    "Phi_K is a new and practical correlation coefficient based on several refinements to Pearson’s hypothesis test of independence of two variables.\n",
    "\n",
    "See:\n",
    "- https://nbviewer.jupyter.org/github/KaveIO/PhiK/blob/master/phik/notebooks/phik_tutorial_basic.ipynb\n",
    "- https://phik.readthedocs.io/en/latest/introduction.html\n",
    "\n",
    "Here we check the usefulness of phik, and to get sense what does it take to have a, for example, 0.3 phik value.\n",
    "\n",
    "The example data below is duplicated 8 times to form the population.\n",
    "\n",
    "<img src=\"image/phik_test_data.png\" width=\"600\"/>\n",
    "\n",
    "Phik values:\n",
    "\n",
    "`col_1 0.50`, `col_2 0.62`, `col_3 0.75`, `col_4 0.34`, `col_5 0.47`, `col_6 0.0`, `col_7 0.10`, `col_8 0.17`, `col_9 0.22`, `col_10 0.57`\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "- Phik generally makes sense and is a useful method for multiclass classification feature selection\n",
    "- Scale of the value has an effect on phik value (see the underlying data for col_4)\n",
    "- The generation of Significance has a random component in it, whereas the calculation of phik doesn’t (the same each time you run it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phik\n",
    "from phik.binning import bin_data\n",
    "from phik.report import plot_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_phik = pd.read_csv(\"test_phik.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_phik.phik_matrix(interval_cols=df_test_phik.columns.tolist()[1:], dropna=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_phik.significance_matrix(interval_cols=df_test_phik.columns.tolist()[1:], dropna=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
